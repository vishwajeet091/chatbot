# chatbot
I made a chatbot using some libraries of  python which takes queries as input from users and provides reasonable response as output. Now the chatbotl required some data to provide responses to the inputs asked by users, so instead of using some outdated csv file or a method that was very common i thought of collecting my own dataset. For this i used a python library called newspaper3k to automatically extract structured information from websites in my case i used a website called mayoclinic.org
Now newspaper3k covers it all it scrapes the article,extracts the information and even summarizes it for us. And then it provides a string format of the entire article 
Once our data was ready in a string variable i tokenized it using a nlp library (What does nlp do NLP is a technological process that allows computers to derive meaning from user text inputs. In doing so, it attempts to understand the intent of the input, rather than just the information about the intent itself, but in my program i didn’t went that deep into it instead i used only one nlp method) called sent_tokenize, Tokenization is a way of separating a piece of text into smaller units called tokens. So with the help of this method i was able to tokenize my data into list of sentences which will later work as outputs to the input the user will be asking.
Then i started with a never ending loop to start the chatbot( by passing true in whilel loop) and i made a conditional statement to check if the user is providing any kind of exit remarks in input like bye, exit, quit then it will break the loop and program will be stopped 
Now i had the data the,what i was supposed to do now was take the user input and provide appropriate response as per the input of the user.
So i appended this user input into the list of sentences
Now count vectorizsers fit_transform function will come into picture we will be using it to create a count matrix for our updated list with the user input and fit_transform function will tokenize the strings and give you a vector for each string, each dimension of which corresponds to the number of times a token is found in the corresponding string. So, fit_transform has determined which tokens it will count, and how they correspond to entries in the count vector. It also gives you the count vectors for the training data.
Later we will find similarity score of out count matrix by passing two arguments user input and everything in the count matrix,Cosine similarity measures the similarity between two vectors of an inner product space. It is measured by the cosine of the angle between two vectors and determines whether two vectors are pointing in roughly the same direction. It is often used to measure document similarity in text analysis.
Then we used similarity_score.flatten() to reduce the dimensions of the similarity score
Then i sorted the indexes of the list containing the cosine similarities in descending order. Index list contains the indices for the highest value of the similarity score.
After sorting it will match 100% with the first element of the list because it is the user text itself so we will slice that accordingly
Now we will use conditional statement to check the similarity score if it matches with the input that we have provided it it matches then it will be greater than 0.0 so if a match will be found then we will return that sentence of the list as response to the users input.
Also there will be times when we will not br able to find a desired response so in that situation we will be using a flag variable if it turns one that means the response was found if it remains 0 then we will return the default response “sorry i did not understand”.
